{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación multiclase\n",
    "##### Nombre: Soria Colque Franz Ronald\n",
    " \n",
    "github: https://github.com/FranzDS01/InteligenciaArtifical/blob/main/Examen%20Laboratorio/Clasificacion_multiclase.ipynb\n",
    "\n",
    " Alumno: Soria Colque Franz Ronald\n",
    " Carrera: Ingenieria de Sistemas\n",
    " Grupo laboratorio: Miercoles\n",
    " Materia: sis420\n",
    "\n",
    "Dataset :https://www.kaggle.com/datasets/uciml/glass\n",
    "\n",
    "Calsificacion de tipo de vidrio \n",
    "Columnas:\n",
    "RI: índice de refracción\n",
    "Na: Sodio (unidad de medida: porcentaje en peso en óxido correspondiente, como son los atributos 4-10)\n",
    "Mg: Magnesio\n",
    "Al: Aluminio\n",
    "Si: Silicio\n",
    "K: Potasio\n",
    "Ca: Calcio\n",
    "Ba: Bario\n",
    "Fe: Hierro\n",
    "Tipo de vidrio:6 tipos\n",
    "\n",
    "Mejor valor de lamnda=0.002\n",
    "Mejor valor de maxIter=1500\n",
    "Mejor valor de theta :\n",
    "[[-1.35484651e-02 -2.43040551e-02 -1.81421535e-01 -3.68109088e-02\n",
    "  -1.90819293e-02 -9.84737673e-01 -7.92232951e-03 -1.22120174e-01\n",
    "  -2.88473920e-03 -3.30582550e-04]\n",
    " [ 1.89656186e+01  1.93975898e-01 -1.12016860e-01  1.86676605e-01\n",
    "  -3.50816074e-01 -2.42674154e-01 -1.25760901e-01 -8.02184625e-02\n",
    "  -4.52411897e-01 -1.09966833e+00]\n",
    " [-1.61651377e+00 -4.27264539e-02 -3.63512451e-01  9.03462918e-02\n",
    "   3.25894494e-02  6.16630311e-02  3.28827025e-03  1.09738519e-01\n",
    "   9.81226155e-02  2.75455887e+00]\n",
    " [ 2.24467555e+01 -6.63300752e-01 -2.02616906e-01  1.19692581e-01\n",
    "  -2.97595063e-01 -2.87098144e-01  1.94180693e-02 -2.74849196e-02\n",
    "   1.08209975e-01 -9.01805344e-01]\n",
    " [-1.35484651e-02 -2.43040551e-02 -1.81421535e-01 -3.68109088e-02\n",
    "  -1.90819293e-02 -9.84737673e-01 -7.92232951e-03 -1.22120174e-01\n",
    "  -2.88473920e-03 -3.30582550e-04]\n",
    " [-2.10186903e+01  9.10684499e-01  1.75128729e-01 -1.38587569e-01\n",
    "   7.06298698e-01  1.69360145e-01  3.97495922e-01  1.41021682e-01\n",
    "  -6.12505514e-01  1.23209096e+00]]\n",
    "\n",
    "  Con datos originales sin los sinteticos el nivel precision alcanza un maximo de 54.14%\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verfficacion de cantidad de clasificaciones que tiene la columna y =\"type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de clases ['D', 'A', 'B', 'C']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8068 entries, 0 to 8067\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               8068 non-null   int64  \n",
      " 1   Gender           8068 non-null   object \n",
      " 2   Ever_Married     7928 non-null   object \n",
      " 3   Age              8068 non-null   int64  \n",
      " 4   Graduated        7990 non-null   object \n",
      " 5   Profession       7944 non-null   object \n",
      " 6   Work_Experience  7239 non-null   float64\n",
      " 7   Spending_Score   8068 non-null   object \n",
      " 8   Family_Size      7733 non-null   float64\n",
      " 9   Var_1            7992 non-null   object \n",
      " 10  Segmentation     8068 non-null   object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 693.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data =pd.read_csv('./Train.csv')\n",
    "value = list(data[\"Segmentation\"].unique())\n",
    "print(\"numero de clases\",value)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 4, 5, 7, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "def csvAdapter(dataset,modificarColumnas,eliminarColumnas):\n",
    "    data =pd.read_csv(dataset,encoding='latin-1')\n",
    "    columna = data.columns\n",
    "    data = data.dropna()\n",
    "    for index in modificarColumnas:\n",
    "        name = columna[index]\n",
    "        value = list(data[name].unique())\n",
    "        data[name] = data[name].map(dict(zip(value,[i for i in range(len(value))])))\n",
    "    #print(data.head())\n",
    "    data = data.drop([columna[index]for index in eliminarColumnas], axis=1)\n",
    "    return data\n",
    "rutadatset='./Train.csv'\n",
    "columnaCategoricas = [i for i in range(0, 11) if not i in [3,6,8]]  # poner columnas que no son categoricas\n",
    "print(columnaCategoricas)\n",
    "eliminarColumnas=[0,9]#columna a eliminar\n",
    "data = csvAdapter(rutadatset, columnaCategoricas,eliminarColumnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de clases [0, 1, 2, 3]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6665 entries, 0 to 8067\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Gender           6665 non-null   int64  \n",
      " 1   Ever_Married     6665 non-null   int64  \n",
      " 2   Age              6665 non-null   int64  \n",
      " 3   Graduated        6665 non-null   int64  \n",
      " 4   Profession       6665 non-null   int64  \n",
      " 5   Work_Experience  6665 non-null   float64\n",
      " 6   Spending_Score   6665 non-null   int64  \n",
      " 7   Family_Size      6665 non-null   float64\n",
      " 8   Segmentation     6665 non-null   int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 520.7 KB\n"
     ]
    }
   ],
   "source": [
    "value = list(data[\"Segmentation\"].unique())\n",
    "print(\"numero de clases\",value)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tres DataFrames diferentes según los valores de la columna 4\n",
    "#data_0 = data[data['Type'] == 0]\n",
    "#data_1 = data[data['Type'] == 1]\n",
    "#data_2 = data[data['Type'] == 2]\n",
    "#data_3 = data[data['Type'] == 3]\n",
    "#data_4 = data[data['Type'] == 4]\n",
    "#data_5 = data[data['Type'] == 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columna_i =data_0.iloc[:,5]\n",
    "#muestras_i=np.random.choice(columna_i,1,replace=True)\n",
    "#print(muestras_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def DatosSinteticosNew(data,listaData,n_filas,clases):\n",
    "    nuevos_datos=np.empty([n_filas,len(data.columns)])\n",
    "    ColmunaY = np.random.randint(0,clases, n_filas)\n",
    "    #print(ColmunaY)\n",
    "    for i in range(len(data.columns)-1):\n",
    "        for j in range(0,n_filas):\n",
    "            pos=ColmunaY[j]\n",
    "            columna_i =listaData[pos].iloc[:,i]\n",
    "            muestras_i=np.random.choice(columna_i,1,replace=True)\n",
    "\n",
    "            probalidad_de_cambio = random.random()\n",
    "            if probalidad_de_cambio<0.2:\n",
    "                muestras_i=muestras_i+probalidad_de_cambio\n",
    "            elif probalidad_de_cambio<0.1:\n",
    "                muestras_i=muestras_i-probalidad_de_cambio\n",
    "            if(i == 0):\n",
    "                muestras_i=muestras_i.round(5)\n",
    "            else:\n",
    "                muestras_i=muestras_i.round(2)\n",
    "            #np.random.seed()\n",
    "            nuevos_datos[j:,i]=muestras_i\n",
    "            nuevos_datos[j:,9]=ColmunaY[j]\n",
    "    columnas =list(data.columns)\n",
    "    print(nuevos_datos)\n",
    "    nuevos_datos_df=pd.DataFrame(nuevos_datos,columns=columnas)\n",
    "    dataExtend =pd.concat([data,nuevos_datos_df],axis=0)\n",
    "    #print(dataExtend.tail())\n",
    "    return dataExtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ListaData=[]\n",
    "for i in range(0,len(value)):\n",
    "    ListaData.append(data[data['Segmentation'] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8055</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8057</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8059</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1757 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Ever_Married  Age  Graduated  Profession  Work_Experience   \n",
       "0          0             0   22          0           0              1.0  \\\n",
       "7          1             0   33          1           0              1.0   \n",
       "8          1             1   61          1           1              0.0   \n",
       "11         0             0   19          0           0              4.0   \n",
       "16         1             0   32          0           5              9.0   \n",
       "...      ...           ...  ...        ...         ...              ...   \n",
       "8055       0             0   18          0           0              0.0   \n",
       "8057       0             1   85          0           2              1.0   \n",
       "8059       0             0   39          1           0              3.0   \n",
       "8064       0             0   35          0           8              3.0   \n",
       "8065       1             0   33          1           0              1.0   \n",
       "\n",
       "      Spending_Score  Family_Size  Segmentation  \n",
       "0                  0          4.0             0  \n",
       "7                  0          3.0             0  \n",
       "8                  0          3.0             0  \n",
       "11                 0          4.0             0  \n",
       "16                 0          5.0             0  \n",
       "...              ...          ...           ...  \n",
       "8055               0          2.0             0  \n",
       "8057               0          1.0             0  \n",
       "8059               0          2.0             0  \n",
       "8064               0          4.0             0  \n",
       "8065               0          1.0             0  \n",
       "\n",
       "[1757 rows x 9 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ListaData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 1 with size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[39m=\u001b[39mDatosSinteticosNew(data,ListaData,\u001b[39m10000\u001b[39;49m,\u001b[39m4\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m data\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mPrueba.csv\u001b[39m\u001b[39m'\u001b[39m,index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[65], line 23\u001b[0m, in \u001b[0;36mDatosSinteticosNew\u001b[1;34m(data, listaData, n_filas, clases)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[39m#np.random.seed()\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         nuevos_datos[j:,i]\u001b[39m=\u001b[39mmuestras_i\n\u001b[1;32m---> 23\u001b[0m         nuevos_datos[j:,\u001b[39m9\u001b[39;49m]\u001b[39m=\u001b[39mColmunaY[j]\n\u001b[0;32m     24\u001b[0m columnas \u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(data\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m     25\u001b[0m \u001b[39mprint\u001b[39m(nuevos_datos)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 9 is out of bounds for axis 1 with size 9"
     ]
    }
   ],
   "source": [
    "data=DatosSinteticosNew(data,ListaData,10000,4)\n",
    "data.to_csv('Prueba.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DatosSinteticosNew(data,listaData,n_filas,clases):\n",
    "    nuevos_datos=np.empty([n_filas,len(data.columns)])\n",
    "    ColmunaY = np.random.randint(0,clases, n_filas)\n",
    "    print(ColmunaY)\n",
    "    for i in range(len(data.columns)-1):\n",
    "        for j in range(0,n_filas):\n",
    "            pos=ColmunaY[j]\n",
    "            columna_i =listaData[pos].iloc[:,i]\n",
    "            muestras_i=np.random.choice(columna_i,1,replace=True)\n",
    "            if(pos == 0):\n",
    "                muestras_i=muestras_i.round(5)\n",
    "            else:\n",
    "                muestras_i=muestras_i.round(3)\n",
    "            #np.random.seed()\n",
    "            nuevos_datos[j:,i]=muestras_i\n",
    "            nuevos_datos[j:,9]=ColmunaY[j]\n",
    "    columnas =list(data.columns)\n",
    "    print(nuevos_datos)\n",
    "    nuevos_datos_df=pd.DataFrame(nuevos_datos,columns=columnas)\n",
    "    dataExtend =pd.concat([data,nuevos_datos_df],axis=0)\n",
    "    #print(dataExtend.tail())\n",
    "    return dataExtend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11063179320448269\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef DatosSinteticosNew(data,data_0,data_1, data_2, data_3, data_4, data_5):\\n    n_filas=10000\\n    nuevos_datos=np.empty([n_filas,len(data.columns)])\\n    ColmunaY = np.random.randint(0, 6, n_filas)\\n    print(ColmunaY)\\n    for i in range(len(data.columns)-1):\\n        for j in range(0,n_filas):\\n            if ColmunaY[j]==0:\\n                columna_i =data_0.iloc[:,i]\\n\\n            if ColmunaY[j]==1:\\n                columna_i =data_1.iloc[:,i]\\n                \\n            if ColmunaY[j]==2:\\n                columna_i =data_2.iloc[:,i]\\n                \\n            if ColmunaY[j]==3:\\n                columna_i =data_3.iloc[:,i]\\n               \\n            if ColmunaY[j]==4:\\n                columna_i =data_4.iloc[:,i]\\n\\n            if ColmunaY[j]==5:\\n                columna_i =data_5.iloc[:,i]\\n\\n            muestras_i=np.random.choice(columna_i,1,replace=True)\\n            if(ColmunaY[j] == 0):\\n                muestras_i=muestras_i.round(5)\\n            else:\\n                muestras_i=muestras_i.round(3)\\n            #np.random.seed()\\n            nuevos_datos[j:,i]=muestras_i\\n            nuevos_datos[j:,9]=ColmunaY[j]\\n    columnas =list(data.columns)\\n    print(nuevos_datos)\\n    nuevos_datos_df=pd.DataFrame(nuevos_datos,columns=columnas)\\n    dataExtend =pd.concat([data,nuevos_datos_df],axis=0)\\n    #print(dataExtend.tail())\\n    return dataExtend\\n'"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def DatosSinteticosNew(data,data_0,data_1, data_2, data_3, data_4, data_5):\n",
    "    n_filas=10000\n",
    "    nuevos_datos=np.empty([n_filas,len(data.columns)])\n",
    "    ColmunaY = np.random.randint(0, 6, n_filas)\n",
    "    print(ColmunaY)\n",
    "    for i in range(len(data.columns)-1):\n",
    "        for j in range(0,n_filas):\n",
    "            if ColmunaY[j]==0:\n",
    "                columna_i =data_0.iloc[:,i]\n",
    "\n",
    "            if ColmunaY[j]==1:\n",
    "                columna_i =data_1.iloc[:,i]\n",
    "                \n",
    "            if ColmunaY[j]==2:\n",
    "                columna_i =data_2.iloc[:,i]\n",
    "                \n",
    "            if ColmunaY[j]==3:\n",
    "                columna_i =data_3.iloc[:,i]\n",
    "               \n",
    "            if ColmunaY[j]==4:\n",
    "                columna_i =data_4.iloc[:,i]\n",
    "\n",
    "            if ColmunaY[j]==5:\n",
    "                columna_i =data_5.iloc[:,i]\n",
    "\n",
    "            muestras_i=np.random.choice(columna_i,1,replace=True)\n",
    "            if(ColmunaY[j] == 0):\n",
    "                muestras_i=muestras_i.round(5)\n",
    "            else:\n",
    "                muestras_i=muestras_i.round(3)\n",
    "            #np.random.seed()\n",
    "            nuevos_datos[j:,i]=muestras_i\n",
    "            nuevos_datos[j:,9]=ColmunaY[j]\n",
    "    columnas =list(data.columns)\n",
    "    print(nuevos_datos)\n",
    "    nuevos_datos_df=pd.DataFrame(nuevos_datos,columns=columnas)\n",
    "    dataExtend =pd.concat([data,nuevos_datos_df],axis=0)\n",
    "    #print(dataExtend.tail())\n",
    "    return dataExtend\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos una lista de dataframes a partir del dataset original de acuerdo a la clasificacion \n",
    "ListaData=[]\n",
    "for i in range(0,len(value)):\n",
    "    ListaData.append(data[data['Type'] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 ... 4 1 0]\n",
      "[[ 1.52227 12.78     3.57    ...  0.       0.       0.     ]\n",
      " [ 1.518   12.16     3.4     ...  0.       0.17     2.     ]\n",
      " [ 1.516   13.1      3.66    ...  0.       0.21     1.     ]\n",
      " ...\n",
      " [ 1.519   14.09     0.      ...  0.       0.       4.     ]\n",
      " [ 1.517   13.09     3.56    ...  0.       0.       1.     ]\n",
      " [ 1.51905 13.05     3.65    ...  0.       0.       0.     ]]\n"
     ]
    }
   ],
   "source": [
    "#ingresamos el dataset orginal,lista de dataFrames, cantidad de datos sinteticos y numero de clases\n",
    "data=DatosSinteticosNew(data,ListaData,10000,6)\n",
    "data.to_csv('Optimizado.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.datasets import make_regression\\nfrom sklearn.linear_model import  LinearRegression\\n\\n#Dataset original\\nnum_filas=data.shape[1]\\n#ajuste al medelo deregresion lineal con datos originales\\nmodel = LinearRegression()\\nmodel.fit(data.iloc[:,:num_filas-1],data.iloc[:,num_filas-1])\\n#Generar datos sinteticos\\nnum_ejemplos =10000\\nX,y=make_regression(n_samples=num_ejemplos,n_features=num_filas-1,noise=0.1)\\n#ajuste de datos sinteticos utilizando el metodo de regresion lineal\\nX=np.round(X)\\ny=model.predict(X)\\ny=np.round(y)\\n#combiar la caracteristicas y la variablidad objetioc en un solo DataFrame\\ndata_sintetico=pd.DataFrame(np.column_stack((X, y)),columns=data.columns)\\n#Guardadar los datos sinteticos en un archivo Csv\\ndata_sintetico.to_csv('datos_sintetico.csv',index=False)\\n\""
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import  LinearRegression\n",
    "\n",
    "#Dataset original\n",
    "num_filas=data.shape[1]\n",
    "#ajuste al medelo deregresion lineal con datos originales\n",
    "model = LinearRegression()\n",
    "model.fit(data.iloc[:,:num_filas-1],data.iloc[:,num_filas-1])\n",
    "#Generar datos sinteticos\n",
    "num_ejemplos =10000\n",
    "X,y=make_regression(n_samples=num_ejemplos,n_features=num_filas-1,noise=0.1)\n",
    "#ajuste de datos sinteticos utilizando el metodo de regresion lineal\n",
    "X=np.round(X)\n",
    "y=model.predict(X)\n",
    "y=np.round(y)\n",
    "#combiar la caracteristicas y la variablidad objetioc en un solo DataFrame\n",
    "data_sintetico=pd.DataFrame(np.column_stack((X, y)),columns=data.columns)\n",
    "#Guardadar los datos sinteticos en un archivo Csv\n",
    "data_sintetico.to_csv('datos_sintetico.csv',index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.mixture import GaussianMixture\\n\\ndef DatosSinteticos(data):\\n    n_filas = 10000\\n    nuevos_datos = np.empty([n_filas, len(data.columns)])\\n    for i in range(len(data.columns)):\\n        columna_i = data.iloc[:, i]\\n        media_i = np.mean(columna_i)\\n        desv_i = np.std(columna_i)\\n        #muestras_i = np.random.normal(media_i, desv_i, n_filas)\\n        muestras_i = np.random.lognormal(mean=np.log(media_i), sigma=desv_i, size=n_filas)\\n        if i==0:\\n            nuevos_datos[:, i] = np.abs(muestras_i).round(4)\\n        if i==9:\\n            muestras_i=np.abs(muestras_i)\\n            muestras_i=np.round(muestras_i).astype(int)\\n            nuevos_datos[:, i] = muestras_i\\n        if i!=0 and i!=9:\\n            nuevos_datos[:, i] = np.abs(muestras_i).round(2)\\n            \\n    columnas = list(data.columns)\\n    nuevos_datos_df = pd.DataFrame(nuevos_datos, columns=columnas)\\n    dataExtend = pd.concat([data, nuevos_datos_df], axis=0)\\n    \\n    # Validación de datos\\n    gmm = GaussianMixture(n_components=len(data.columns))\\n    gmm.fit(dataExtend)\\n    scores = gmm.score_samples(dataExtend)\\n    threshold = np.percentile(scores, 5)\\n    dataExtend = dataExtend[scores >= threshold]\\n    \\n    return dataExtend\\n\\ndata=DatosSinteticos(data)\\ndata.to_csv('data_sintetico.csv',index=False)\\n\""
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def DatosSinteticos(data):\n",
    "    n_filas = 10000\n",
    "    nuevos_datos = np.empty([n_filas, len(data.columns)])\n",
    "    for i in range(len(data.columns)):\n",
    "        columna_i = data.iloc[:, i]\n",
    "        media_i = np.mean(columna_i)\n",
    "        desv_i = np.std(columna_i)\n",
    "        #muestras_i = np.random.normal(media_i, desv_i, n_filas)\n",
    "        muestras_i = np.random.lognormal(mean=np.log(media_i), sigma=desv_i, size=n_filas)\n",
    "        if i==0:\n",
    "            nuevos_datos[:, i] = np.abs(muestras_i).round(4)\n",
    "        if i==9:\n",
    "            muestras_i=np.abs(muestras_i)\n",
    "            muestras_i=np.round(muestras_i).astype(int)\n",
    "            nuevos_datos[:, i] = muestras_i\n",
    "        if i!=0 and i!=9:\n",
    "            nuevos_datos[:, i] = np.abs(muestras_i).round(2)\n",
    "            \n",
    "    columnas = list(data.columns)\n",
    "    nuevos_datos_df = pd.DataFrame(nuevos_datos, columns=columnas)\n",
    "    dataExtend = pd.concat([data, nuevos_datos_df], axis=0)\n",
    "    \n",
    "    # Validación de datos\n",
    "    gmm = GaussianMixture(n_components=len(data.columns))\n",
    "    gmm.fit(dataExtend)\n",
    "    scores = gmm.score_samples(dataExtend)\n",
    "    threshold = np.percentile(scores, 5)\n",
    "    dataExtend = dataExtend[scores >= threshold]\n",
    "    \n",
    "    return dataExtend\n",
    "\n",
    "data=DatosSinteticos(data)\n",
    "data.to_csv('data_sintetico.csv',index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de clases [0.0, 1.0, 2.0, 3.0]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16665 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Gender           16665 non-null  float64\n",
      " 1   Ever_Married     16665 non-null  float64\n",
      " 2   Age              16665 non-null  float64\n",
      " 3   Graduated        16665 non-null  float64\n",
      " 4   Profession       16665 non-null  float64\n",
      " 5   Work_Experience  16665 non-null  float64\n",
      " 6   Spending_Score   16665 non-null  float64\n",
      " 7   Family_Size      16665 non-null  float64\n",
      " 8   Var_1            16665 non-null  float64\n",
      " 9   Segmentation     16665 non-null  float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "value = list(data[\"Segmentation\"].unique())\n",
    "print(\"numero de clases\",value)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "def DatosSinteticos(data):\n",
    "    n_filas = 10000\n",
    "    nuevos_datos = np.empty([n_filas, len(data.columns)])\n",
    "    for i in range(len(data.columns)):\n",
    "        columna_i = data.iloc[:, i]\n",
    "        media_i = np.mean(columna_i)\n",
    "        desv_i = np.std(columna_i)\n",
    "        muestras_i = np.random.lognormal(mean=np.log(media_i), sigma=desv_i, size=n_filas)\n",
    "        muestras_i = np.abs(muestras_i) # Convertir cualquier valor negativo en su valor absoluto\n",
    "        nuevos_datos[:, i] = muestras_i\n",
    "    columnas = list(data.columns)\n",
    "    nuevos_datos_df = pd.DataFrame(nuevos_datos, columns=columnas)\n",
    "    dataExtend = pd.concat([data, nuevos_datos_df], axis=0)\n",
    "    \n",
    "    # Validación de datos\n",
    "    gmm = GaussianMixture(n_components=len(data.columns))\n",
    "    gmm.fit(dataExtend)\n",
    "    scores = gmm.score_samples(dataExtend)\n",
    "    threshold = np.percentile(scores, 5)\n",
    "    dataExtend = dataExtend[scores >= threshold]\n",
    "    \n",
    "    return dataExtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DatosSinteticos(data):\n",
    "    n_filas=10000\n",
    "    nuevos_datos=np.empty([n_filas,len(data.columns)])\n",
    "    for i in range(len(data.columns)):\n",
    "        columna_i =data.iloc[:,i]\n",
    "        muestras_i=np.random.choice(columna_i,n_filas,replace=True)\n",
    "        nuevos_datos[:,i]=muestras_i.round()\n",
    "    columnas =list(data.columns)\n",
    "    nuevos_datos_df=pd.DataFrame(nuevos_datos,columns=columnas)\n",
    "    dataExtend =pd.concat([data,nuevos_datos_df],axis=0)\n",
    "    #print(dataExtend.tail())\n",
    "    return dataExtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9)\n"
     ]
    }
   ],
   "source": [
    "num_labels = 6\n",
    "X, y = data[0:10000, :9], data[0:10000, 9]\n",
    "Xprueba=data[10000:,:9]\n",
    "yprueba=data[10000:,9]\n",
    "m = y.size\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6665, 9)\n",
      "(10000, 9)\n"
     ]
    }
   ],
   "source": [
    "print(Xprueba.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.   22.   ...  0.    4.    0.  ]\n",
      " [ 1.    1.   67.   ...  0.    1.    1.  ]\n",
      " [ 0.    1.   67.   ...  1.    2.    1.  ]\n",
      " ...\n",
      " [ 0.    1.   77.   ...  0.    5.    3.  ]\n",
      " [ 1.    0.   52.   ...  0.    4.19  1.  ]\n",
      " [ 1.    1.   49.   ...  1.    1.13  1.  ]]\n",
      "[0. 1. 1. ... 1. 3. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores de prueba para los parámetros theta\n",
    "theta_t = np.array([-2, -1, 1, 2], dtype=float)\n",
    "\n",
    "# valores de prueba para las entradas\n",
    "X_t = np.concatenate([np.ones((5, 1)), np.arange(1, 16).reshape(5, 3, order='F')/10.0], axis=1)\n",
    "\n",
    "# valores de testeo para las etiquetas\n",
    "y_t = np.array([1, 0, 1, 0, 1])\n",
    "\n",
    "# valores de testeo para el parametro de regularizacion\n",
    "lambda_t = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcula la sigmoide de z.\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrCostFunction(theta, X, y, lambda_):\n",
    " \n",
    "#     alpha = 0.003\n",
    "#     theta = theta.copy()\n",
    "    # Inicializa algunos valores utiles\n",
    "    m = y.size\n",
    "    epsilon = 1e-8 \n",
    "    # convierte las etiquetas a valores enteros si son boleanos\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "    \n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "    \n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    \n",
    "    temp = theta\n",
    "    temp[0] = 0\n",
    "    \n",
    "#     J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h+epsilon)) - (1 - y).dot(np.log(1 - h+epsilon))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
    "    \n",
    "    grad = (1 / m) * (h - y).dot(X)\n",
    "#     theta = theta - (alpha / m) * (h - y).dot(X)\n",
    "    grad = grad + (lambda_ / m) * temp\n",
    "\n",
    "    return J, grad\n",
    "#    return J, theta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Vectorización regularizada de la regresión logística\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costo         : 2.534819\n",
      "-----------------------\n",
      "Gradientes:\n",
      " [0.146561, -0.548558, 0.724722, 1.398003]\n",
      "Gradientes esperados:\n",
      " [0.146561, -0.548558, 0.724722, 1.398003]\n"
     ]
    }
   ],
   "source": [
    "J, grad = lrCostFunction(theta_t, X_t, y_t, lambda_t)\n",
    "\n",
    "print('Costo         : {:.6f}'.format(J))\n",
    "print('-----------------------')\n",
    "print('Gradientes:')\n",
    "print(' [{:.6f}, {:.6f}, {:.6f}, {:.6f}]'.format(*grad))\n",
    "print('Gradientes esperados:')\n",
    "print(' [0.146561, -0.548558, 0.724722, 1.398003]');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "### 1.4 Clasificacion One-vs-all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(X, y, num_labels, lambda_):\n",
    "\n",
    "    # algunas variables utiles\n",
    "    m, n = X.shape\n",
    "    \n",
    "    all_theta = np.zeros((num_labels, n + 1))\n",
    "\n",
    "    # Agrega unos a la matriz X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    for c in np.arange(num_labels):\n",
    "        initial_theta = np.zeros(n + 1)\n",
    "        options = {'maxiter': 800}\n",
    "        res = optimize.minimize(lrCostFunction, \n",
    "                                initial_theta, \n",
    "                                (X, (y == c), lambda_), \n",
    "                                jac=True, \n",
    "                                method='CG',\n",
    "                                options=options) \n",
    "        \n",
    "        all_theta[c] = res.x\n",
    "\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOneVsAll(all_theta, X):\n",
    "    m = X.shape[0];\n",
    "    num_labels = all_theta.shape[0]\n",
    "\n",
    "    p = np.zeros(m)\n",
    "\n",
    "    # Add ones to the X data matrix\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 10)\n",
      "[[ 2.06380499e+00 -3.92452335e-01 -7.57306442e-01 -3.73102166e-02\n",
      "  -1.26472704e+00 -1.20273129e-01  3.26337254e-02 -7.42880306e-01\n",
      "   1.09849099e-01 -2.84265529e-02]\n",
      " [-2.31283993e+00  1.25833082e-01  4.15097624e-01  1.10073114e-02\n",
      "   3.56377862e-01  4.91171370e-02 -1.29347827e-02  1.71378403e-01\n",
      "  -8.45763592e-02  4.89961076e-02]\n",
      " [-3.80891801e+00  1.88944086e-01  4.50259133e-01  1.51574904e-02\n",
      "   1.15167030e+00 -9.29618821e-03 -3.51852266e-02  6.59696396e-01\n",
      "   1.41730048e-01 -2.17014097e-03]\n",
      " [-8.43975847e-01  1.76875468e-02  1.32217358e-01  3.33763355e-03\n",
      "  -5.49268467e-02  1.01994130e-01  2.03890758e-02 -4.41709530e-01\n",
      "  -2.17903770e-01 -3.56449597e-02]\n",
      " [-2.30627463e-02 -1.05659301e-02 -1.37705813e-02 -1.00198634e+00\n",
      "  -1.47808910e-02 -7.62261126e-02 -6.05068215e-02 -1.50206513e-02\n",
      "  -6.57612762e-02 -3.24050958e-02]\n",
      " [-2.30627463e-02 -1.05659301e-02 -1.37705813e-02 -1.00198634e+00\n",
      "  -1.47808910e-02 -7.62261126e-02 -6.05068215e-02 -1.50206513e-02\n",
      "  -6.57612762e-02 -3.24050958e-02]]\n"
     ]
    }
   ],
   "source": [
    "lambda_ = 0.03 #mejor lambda es 0.002\n",
    "all_theta = oneVsAll(X, y, num_labels, lambda_)\n",
    "print(all_theta.shape)\n",
    "print(all_theta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9)\n",
      "Precision del conjuto de entrenamiento: 47.73%\n",
      "se espera de clase : 0.0\n",
      "La clase es:  [2]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "pred = predictOneVsAll(all_theta, X)\n",
    "print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == y) * 100))\n",
    "XPrueba = Xprueba[40:41, :].copy()\n",
    "y_p=yprueba[40]\n",
    "print(\"se espera de clase :\",y_p)\n",
    "XPrueba = np.concatenate([np.ones((1, 1)), XPrueba], axis=1)\n",
    "p = np.argmax(sigmoid(XPrueba.dot(all_theta.T)), axis = 1)\n",
    "print(\"La clase es: \", p)\n",
    "\n",
    "#displayData(X[1002:1003, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
